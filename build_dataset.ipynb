{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPedia Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a procedure to retrieve and dump the [SNPedia](https://www.snpedia.com/) data and store it in a CSV files for further processing. The data is distributed under a [Creative Commons Attribution-Noncommercial-Share Alike 3.0 United States License](http://creativecommons.org/licenses/by-nc-sa/3.0/us/). The SNPedia explicitly allows scraping of the data and provides a [Bulk API](https://www.snpedia.com/index.php/Bulk) to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Python 3.12 or higher is required. The following packages are required:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dima/dev/cm3010-databases-and-advanced-data-techniques-midterm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from itertools import batched\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "import requests\n",
    "import mwparserfromhell\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are scraping the data from the web, we need to be prepared for occasional HTTP errors. We will use a `Retry` package to specify a retry strategy for the HTTP requests to be able to recover from these errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "retry_strategy = Retry(\n",
    "    # max retries\n",
    "    total=3,\n",
    "\n",
    "    # 1 second initial backoff, 2x each subsequent backoff\n",
    "    backoff_factor=1,\n",
    "\n",
    "    # errors for which we retry\n",
    "    status_forcelist=[429, 500, 502, 503, 504]\n",
    ")\n",
    "\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", adapter)\n",
    "http.mount(\"http://\", adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_titles_in_category(category_name: str) -> [str]:\n",
    "    \"\"\"\n",
    "    Fetches all titles in a category from the SNPedia API\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Fetching titles in category {category_name}\", end=\"\")\n",
    "\n",
    "    titles = []\n",
    "    cmcontinue = \"\"\n",
    "    while True:\n",
    "        print(\".\", end=\"\")\n",
    "        response = http.get(f'https://bots.snpedia.com/api.php?action=query&list=categorymembers&cmtitle=Category:{category_name}&cmlimit=500&format=json&cmcontinue={cmcontinue}')\n",
    "\n",
    "        # ensure the API call was successful\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # add the snps to the list\n",
    "        for snp in response.json()['query']['categorymembers']:\n",
    "            titles.append(snp['title'])\n",
    "\n",
    "        # we use the cmcontinue value in the next API call to get the next page of the results\n",
    "        if response.json().get('continue'):\n",
    "            cmcontinue = response.json()['continue']['cmcontinue']\n",
    "        else:\n",
    "            # stop iterating if there are no more pages to fetch\n",
    "            break\n",
    "\n",
    "        if cmcontinue == '0|0':\n",
    "            break\n",
    "\n",
    "    print(\"done\")\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pages(titles: [str]) -> [dict]:\n",
    "    \"\"\"\n",
    "    Fetches the content of a list of pages from the SNPedia API\n",
    "    \"\"\"\n",
    "\n",
    "    # request 50 pages at a time (the maximum allowed)\n",
    "    response = http.get('https://bots.snpedia.com/api.php?action=query&prop=revisions&rvslots=*&rvprop=content&format=json&titles={}'.format('|'.join(titles)))\n",
    "\n",
    "    # ensure the API call was successful\n",
    "    response.raise_for_status()\n",
    "\n",
    "    pages = []\n",
    "    for page in response.json()['query']['pages'].values():\n",
    "        # snp is the title of the page\n",
    "        title = page['title']\n",
    "\n",
    "        # text is the content of the page\n",
    "        text = page['revisions'][0]['slots']['main']['*']\n",
    "\n",
    "        # add the snp and text to the list\n",
    "        pages.append({'title': title, 'text': text})\n",
    "    \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_template_params(text, template_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts all the parameters from a template in the wikitext\n",
    "    \"\"\"\n",
    "\n",
    "    templates = mwparserfromhell.parse(text).filter_templates()\n",
    "\n",
    "    matched_templates = [template for template in templates if template.name.strip().lower() == template_name.lower()]\n",
    "    if not matched_templates:\n",
    "        return {}\n",
    "\n",
    "    template = matched_templates[0]\n",
    "    return dict([[param.name.strip(), param.value.strip()] for param in template.params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump SNP pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to fetch a list of all pages that describe SNPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching titles in category Is_a_snp................................................................................................................................................................................................................................done\n"
     ]
    }
   ],
   "source": [
    "snps = fetch_titles_in_category(\"Is_a_snp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a list of SNPs to a file to avoid fetching it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(snps, open('dataset/snps.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = pickle.load(open('dataset/snps.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas dataframe to store the pages data in a row format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the content of each SNP's page and store it in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2235it [23:10,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# split the list of snps into batches of 50\n",
    "for batch in tqdm(batched(snps, 50)):\n",
    "    pages = fetch_pages(batch)\n",
    "\n",
    "    # add new data to the dataframe\n",
    "    new_df = pd.DataFrame(pages, columns=['title', 'text'])\n",
    "    df = pd.concat([df, new_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe in its initial form to a file to avoid fetching it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dataset/snps_pages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('dataset/snps_pages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'title': 'ID'}, inplace=True)\n",
    "df.set_index('ID', inplace=True)\n",
    "df.index = df.index.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a pure page content (without any Wikitext templates) as a \"description\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Description\"] = df[\"text\"].apply(lambda x: mwparserfromhell.parse(x).strip_code())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/snps.csv', columns=['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Rsnum template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rsnum(item):\n",
    "    return extract_template_params(item[\"text\"], \"Rsnum\")\n",
    "\n",
    "rsnum_df = df.apply(parse_rsnum, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the attributes of the `Rsnum` template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rsnum_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrsnum_df\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rsnum_df' is not defined"
     ]
    }
   ],
   "source": [
    "rsnum_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsnum_df.to_csv('dataset/rsnums.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse ClinVar template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clinvar(item):\n",
    "    return extract_template_params(item[\"text\"], \"ClinVar\")\n",
    "\n",
    "clinvar_df = df.apply(parse_clinvar, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the attributes of the `ClinVar` template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALT</th>\n",
       "      <th>CAF</th>\n",
       "      <th>CHROM</th>\n",
       "      <th>CLNACC</th>\n",
       "      <th>CLNALLE</th>\n",
       "      <th>CLNDBN</th>\n",
       "      <th>CLNDSDB</th>\n",
       "      <th>CLNDSDBID</th>\n",
       "      <th>CLNHGVS</th>\n",
       "      <th>CLNORIGIN</th>\n",
       "      <th>CLNREVSTAT</th>\n",
       "      <th>CLNSIG</th>\n",
       "      <th>CLNSRC</th>\n",
       "      <th>CLNSRCID</th>\n",
       "      <th>COMMON</th>\n",
       "      <th>Disease</th>\n",
       "      <th>FwdALT</th>\n",
       "      <th>FwdREF</th>\n",
       "      <th>GENEINFO</th>\n",
       "      <th>GENE_ID</th>\n",
       "      <th>GENE_NAME</th>\n",
       "      <th>REF</th>\n",
       "      <th>RSPOS</th>\n",
       "      <th>Reversed</th>\n",
       "      <th>SAO</th>\n",
       "      <th>SSR</th>\n",
       "      <th>Tags</th>\n",
       "      <th>VC</th>\n",
       "      <th>VP</th>\n",
       "      <th>WGT</th>\n",
       "      <th>dbSNPBuildID</th>\n",
       "      <th>rsid</th>\n",
       "      <th>GMAF</th>\n",
       "      <th>CLNCUI</th>\n",
       "      <th>RS</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69584</td>\n",
       "      <td>6507</td>\n",
       "      <td>69584</td>\n",
       "      <td>66857</td>\n",
       "      <td>69583</td>\n",
       "      <td>67013</td>\n",
       "      <td>66180</td>\n",
       "      <td>66180</td>\n",
       "      <td>69584</td>\n",
       "      <td>67227</td>\n",
       "      <td>66568</td>\n",
       "      <td>69480</td>\n",
       "      <td>37301</td>\n",
       "      <td>36528</td>\n",
       "      <td>6507</td>\n",
       "      <td>66978</td>\n",
       "      <td>69175</td>\n",
       "      <td>69427</td>\n",
       "      <td>68997</td>\n",
       "      <td>68997</td>\n",
       "      <td>68997</td>\n",
       "      <td>69584</td>\n",
       "      <td>69584</td>\n",
       "      <td>69584</td>\n",
       "      <td>69583</td>\n",
       "      <td>69583</td>\n",
       "      <td>69584</td>\n",
       "      <td>69584</td>\n",
       "      <td>69583</td>\n",
       "      <td>69583</td>\n",
       "      <td>69584</td>\n",
       "      <td>69585</td>\n",
       "      <td>1705</td>\n",
       "      <td>10753</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1771</td>\n",
       "      <td>2333</td>\n",
       "      <td>25</td>\n",
       "      <td>66245</td>\n",
       "      <td>37</td>\n",
       "      <td>14337</td>\n",
       "      <td>1782</td>\n",
       "      <td>13491</td>\n",
       "      <td>69063</td>\n",
       "      <td>110</td>\n",
       "      <td>287</td>\n",
       "      <td>10</td>\n",
       "      <td>246</td>\n",
       "      <td>36120</td>\n",
       "      <td>2</td>\n",
       "      <td>12614</td>\n",
       "      <td>1471</td>\n",
       "      <td>2515</td>\n",
       "      <td>4731</td>\n",
       "      <td>4699</td>\n",
       "      <td>4731</td>\n",
       "      <td>3097</td>\n",
       "      <td>67045</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5912</td>\n",
       "      <td>5</td>\n",
       "      <td>5916</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>69585</td>\n",
       "      <td>575</td>\n",
       "      <td>2770</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A</td>\n",
       "      <td>0.9998; 0.0001997</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>not provided</td>\n",
       "      <td>MedGen</td>\n",
       "      <td>CN221809</td>\n",
       "      <td>NC_000013.10:g.32907428dupA</td>\n",
       "      <td>1</td>\n",
       "      <td>single</td>\n",
       "      <td>5</td>\n",
       "      <td>OMIM Allelic Variant</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>not provided</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>BRCA2:675</td>\n",
       "      <td>675</td>\n",
       "      <td>BRCA2</td>\n",
       "      <td>G</td>\n",
       "      <td>55242466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PM;NSF;REF;ASP;LSD</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0x050060001205000002100200</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>10010131</td>\n",
       "      <td>0.0005</td>\n",
       "      <td></td>\n",
       "      <td>1143016</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>16674</td>\n",
       "      <td>1485</td>\n",
       "      <td>6144</td>\n",
       "      <td>121</td>\n",
       "      <td>61219</td>\n",
       "      <td>10156</td>\n",
       "      <td>13377</td>\n",
       "      <td>10149</td>\n",
       "      <td>4</td>\n",
       "      <td>55397</td>\n",
       "      <td>25904</td>\n",
       "      <td>45359</td>\n",
       "      <td>11394</td>\n",
       "      <td>121</td>\n",
       "      <td>4289</td>\n",
       "      <td>10156</td>\n",
       "      <td>14777</td>\n",
       "      <td>21016</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>19097</td>\n",
       "      <td>9</td>\n",
       "      <td>40132</td>\n",
       "      <td>41803</td>\n",
       "      <td>69436</td>\n",
       "      <td>3274</td>\n",
       "      <td>50377</td>\n",
       "      <td>5093</td>\n",
       "      <td>68904</td>\n",
       "      <td>7649</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ALT                CAF  CHROM CLNACC CLNALLE        CLNDBN CLNDSDB  \\\n",
       "count   69584               6507  69584  66857   69583         67013   66180   \n",
       "unique   1771               2333     25  66245      37         14337    1782   \n",
       "top         A  0.9998; 0.0001997      2              1  not provided  MedGen   \n",
       "freq    16674               1485   6144    121   61219         10156   13377   \n",
       "\n",
       "       CLNDSDBID                      CLNHGVS CLNORIGIN CLNREVSTAT CLNSIG  \\\n",
       "count      66180                        69584     67227      66568  69480   \n",
       "unique     13491                        69063       110        287     10   \n",
       "top     CN221809  NC_000013.10:g.32907428dupA         1     single      5   \n",
       "freq       10149                            4     55397      25904  45359   \n",
       "\n",
       "                      CLNSRC CLNSRCID COMMON       Disease FwdALT FwdREF  \\\n",
       "count                  37301    36528   6507         66978  69175  69427   \n",
       "unique                   246    36120      2         12614   1471   2515   \n",
       "top     OMIM Allelic Variant               1  not provided      T      G   \n",
       "freq                   11394      121   4289         10156  14777  21016   \n",
       "\n",
       "         GENEINFO GENE_ID GENE_NAME    REF     RSPOS Reversed    SAO    SSR  \\\n",
       "count       68997   68997     68997  69584     69584    69584  69583  69583   \n",
       "unique       4731    4699      4731   3097     67045        2      3      3   \n",
       "top     BRCA2:675     675     BRCA2      G  55242466        0      1      0   \n",
       "freq         2691    2691      2691  19097         9    40132  41803  69436   \n",
       "\n",
       "                      Tags     VC                          VP    WGT  \\\n",
       "count                69584  69584                       69583  69583   \n",
       "unique                5912      5                        5916      2   \n",
       "top     PM;NSF;REF;ASP;LSD    SNV  0x050060001205000002100200      1   \n",
       "freq                  3274  50377                        5093  68904   \n",
       "\n",
       "       dbSNPBuildID      rsid    GMAF CLNCUI       RS Risk  \n",
       "count         69584     69585    1705  10753       29    1  \n",
       "unique           65     69585     575   2770       29    1  \n",
       "top             137  10010131  0.0005         1143016    G  \n",
       "freq           7649         1     297    953        1    1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinvar_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_df.to_csv('dataset/clinvars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse PMIDs template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pmids(item):\n",
    "    wikitext = mwparserfromhell.parse(text)\n",
    "    templates = wikitext.filter_templates()\n",
    "    pmids = [{\"PMID\": template.params[0].value.strip(), \"Title\": ''} for template in templates if template.name.strip() == \"PMID\"]\n",
    "    pmids += [{\"PMID\": template.get(\"PMID\").value.strip(), \"Title\": template.get(\"Title\").value.strip()} for template in templates if template.name.strip() == \"PMID Auto\"]\n",
    "    return pmids\n",
    "\n",
    "pmids_df_orig = df.apply(parse_pmids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids_df = pd.DataFrame(pmids_df_orig.explode())\n",
    "normalized_pmid_title = pd.json_normalize(pmids_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pmid_title.index = pmids_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pmid_title.to_csv('dataset/pmids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_categories(item):\n",
    "    wikitext = mwparserfromhell.parse(item[\"text\"])\n",
    "    templates = wikitext.filter_templates()\n",
    "\n",
    "    categories = []\n",
    "    if [template for template in templates if template.name.strip().lower() == \"interesting\"]:\n",
    "        categories.append(\"Interesting\")\n",
    "\n",
    "    on_chip_templates = [template for template in templates if template.name.strip().lower() == \"on chip\"]\n",
    "    on_chip_categories = [\"On chip \" + template.params[0].value.strip() for template in on_chip_templates]\n",
    "    categories += on_chip_categories\n",
    "\n",
    "    return(categories)\n",
    "\n",
    "categories_df_orig = df.apply(parse_categories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(categories_df_orig, columns=[\"name\"]).explode(\"name\").to_csv('dataset/categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Genotype pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch a list of genotypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching titles in category Is_a_genotype..................................................................................................................................................................................................................done\n"
     ]
    }
   ],
   "source": [
    "genotypes = fetch_titles_in_category(\"Is_a_genotype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a list of genotypes to a file to avoid fetching it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(genotypes, open('dataset/genotypes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = pickle.load(open('dataset/genotypes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2097it [55:29,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# split the list of genotypes into batches of 50\n",
    "for batch in tqdm(batched(genotypes, 50)):\n",
    "    time.sleep(1)\n",
    "    pages = fetch_pages(batch)\n",
    "\n",
    "    # add new data to the dataframe\n",
    "    new_df = pd.DataFrame(pages, columns=['title', 'text'])\n",
    "    df = pd.concat([df, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dataset/genotypes_pages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('dataset/genotypes_pages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('title', inplace=True)\n",
    "df[\"genotype\"] = df.index.str.extract(r'\\((.*)\\)', expand=False)\n",
    "df[\"snp\"] = df.index.str.extract(r'(.*)\\(.*\\)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"snp\"] = df[\"snp\"].str.lower()\n",
    "df[\"description\"] = df[\"text\"].apply(lambda x: mwparserfromhell.parse(x).strip_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the genotype information from the SNPedia's Genotype template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genotype_template_params(item):\n",
    "    return extract_template_params(item[\"text\"], \"Genotype\")\n",
    "\n",
    "template_df = df.apply(extract_genotype_template_params, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, template_df[[\"allele1\", \"allele2\", \"magnitude\", \"repute\", \"summary\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the genotype information to a resulting CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/genotypes.csv', index=False, columns=['snp', 'allele1', 'allele2', 'magnitude', 'repute', 'summary', 'description'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
